{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning: Cats vs. Dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imshow, imresize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(max_files=float(\"inf\")):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Load images\n",
    "    counter = [0, 0]\n",
    "    for _file in os.listdir(\"data/train\"):\n",
    "        category = 1 if \"cat\" in _file else 0\n",
    "        # Leading all 20k images takes a long time. For testing purposes, we want to reduce the number of examples.\n",
    "        if counter[category] < max_files:\n",
    "            img = imread(os.path.join(\"data/train\", _file), flatten=True)\n",
    "            img = imresize(img, size=(128,128)).flatten()\n",
    "            X.append(img)\n",
    "            y.append(category)\n",
    "            counter[category] += 1\n",
    "    return np.stack(X), np.array(y)\n",
    "\n",
    "\n",
    "def split_dataset(X, y):\n",
    "    X_num = X.shape[0]\n",
    "    indicies = np.random.permutation(X_num)\n",
    "    split_idx = int(X_num * 0.8)\n",
    "    X_data, y_data = X[indicies[:split_idx]], y[indicies[:split_idx]]\n",
    "    X_test, y_test = X[indicies[split_idx:]], y[indicies[split_idx:]]\n",
    "\n",
    "    return X_data, y_data, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the dataset. This may take a while...\n",
    "X, y = load_dataset(max_files=300)\n",
    "\n",
    "# Split the dataset into training and test\n",
    "X_train, y_train, X_test, y_test = split_dataset(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: KNeighborsClassifier     Score: 0.575\n",
      "Classifier: SVC                      Score: 0.483333333333\n",
      "Classifier: DecisionTreeClassifier   Score: 0.45\n"
     ]
    }
   ],
   "source": [
    "classifiers = [KNeighborsClassifier, SVC, DecisionTreeClassifier]\n",
    "\n",
    "for clf_class in classifiers:\n",
    "    clf = clf_class()\n",
    "    clf.fit(X_train, y_train)\n",
    "    result = clf.score(X_test, y_test)\n",
    "    print \"Classifier: {cls:25}Score: {score}\".format(cls=clf.__class__.__name__, score=result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
